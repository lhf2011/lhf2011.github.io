<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title> imageSentimentClassification - Kaggle Competition | Gridea</title>
<link rel="shortcut icon" href="https://lhf2011.github.io/favicon.ico?v=1603664829242">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://lhf2011.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title=" imageSentimentClassification - Kaggle Competition | Gridea - Atom Feed" href="https://lhf2011.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="Resources
My code
dataset
Task
Image classification and explain your model.

Data augmentation
In the training data set,..." />
    <meta name="keywords" content="Kaggle,classification,Keras,data augement,image preprocessing,neuron visualization,deep learning" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://lhf2011.github.io">
  <img class="avatar" src="https://lhf2011.github.io/images/avatar.png?v=1603664829242" alt="">
  </a>
  <h1 class="site-title">
    Gridea
  </h1>
  <p class="site-description">
    Be good. 
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          Index
        </a>
      
    
      
        <a href="/archives" class="menu">
          Archives
        </a>
      
    
      
        <a href="/tags" class="menu">
          Tags
        </a>
      
    
      
        <a href="/post/about" class="menu">
          About
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
               imageSentimentClassification - Kaggle Competition
            </h2>
            <div class="post-info">
              <span>
                2020-09-01
              </span>
              <span>
                4 min read
              </span>
              
                <a href="https://lhf2011.github.io/tag/oWZ2R-KNi/" class="post-tag">
                  # Kaggle
                </a>
              
                <a href="https://lhf2011.github.io/tag/FZWGS-rnV/" class="post-tag">
                  # classification
                </a>
              
                <a href="https://lhf2011.github.io/tag/XAqJFhoDc/" class="post-tag">
                  # Keras
                </a>
              
                <a href="https://lhf2011.github.io/tag/cCp5VWMET/" class="post-tag">
                  # data augement
                </a>
              
                <a href="https://lhf2011.github.io/tag/yWKcOGLnr/" class="post-tag">
                  # image preprocessing
                </a>
              
                <a href="https://lhf2011.github.io/tag/pEtQGz_u8/" class="post-tag">
                  # neuron visualization
                </a>
              
                <a href="https://lhf2011.github.io/tag/ypuNEPGzd/" class="post-tag">
                  # deep learning
                </a>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <h1 id="resources">Resources</h1>
<p><a href="https://github.com/lhf2011/imageSentimentClassification">My code</a><br>
<a href="https://drive.google.com/drive/folders/11VtTjflPaHVZCYuXjtpVAHcis6tbkq9w">dataset</a></p>
<h1 id="task">Task</h1>
<p>Image classification and explain your model.<br>
<img src="../../post-images/20200910_rawImage.jpg" width="500" height="100" align=center /></p>
<h1 id="data-augmentation">Data augmentation</h1>
<p>In the training data set, faces in different sizes and positions, different tilting angles, and some facing left but some others are in the right direction. These unimportant features allow us to modify them to enrich our training data set. The Keras ImageDataGenerator is a function that can transform images randomly, within the user defined restrictions. In this project, the restrictions defined as</p>
<pre><code>datagen = ImageDataGenerator(rotation_range=40, zoom_range=0.4, width_shift_range = 0.2, height_shift_range=0.2,
                                 shear_range=0.1, horizontal_flip=True,
                                 fill_mode='nearest', dtype='uint8')
</code></pre>
<p>Those generated images can reduce overfitting, and this kind of data augement method can reduce memory usage.</p>
<h1 id="image-contrast-enhancement">Image Contrast Enhancement</h1>
<p>In our training data, some images are too dark or too bright, it's hard to see faces. To avoid the effects of light, histogram equalization was used to balance pixel distribution and adjust the picture contrast.</p>
<pre><code class="language-python">    # statistical gray scale distribution
    def calcHistogram(self,image):
        grayStatistic = [0] * 256  # how many pixels in each gray scale
        w = image.shape[0]
        h = image.shape[1]
        for i in range(w):
            for j in range(h):
                gray = image[i, j]
                grayStatistic[gray] += 1
        return grayStatistic

    # according to the gray scale distribution of a image, make equalization
    def histEqualization(self,grayStatistic, image):
        b = [0] * 256  # save gray scale ratio
        c = [0] * 256  # save accumulated counts
        w = image.shape[0]
        h = image.shape[1]
        mn = w * h * 1.0
        img = np.zeros([w, h], np.uint8)  # save img after equalization
        for i in range(len(grayStatistic)):
            b[i] = grayStatistic[i] / mn
        # accumulate
        for i in range(len(c)):
            if i == 1:
                c[i] = b[i]
            else:
                c[i] = c[i - 1] + b[i]
                grayStatistic[i] = int(255 * c[i])
        # equalization
        for i in range(w):
            for j in range(h):
                img[i, j] = grayStatistic[image[i, j]]
        return img
</code></pre>
<h1 id="model">Model</h1>
<p>The model is a combination of truncated Vgg16 and NiN. I take 3 blocks of Vgg16, connected with a NiN block. The NiN is Network-In-Network, it has two significant improvements in neural network, one is MLP-conv(multilayer perceptron), and the other one is GAP(global average pooling). In my project, the MLP-conv consists of a 3x3 conv layer and two 1x1 conv layers. To avoid gradient vanish and overfitting, batch normalization is added between 3x3 conv layer and “Relu” activation, and Dropout follows 1x1 conv layer. The GAP layer takes the average of each feature map, the resulting vector is fed directly into the softmax layer.</p>
<img src="../../post-images/20200910_1.jpg" width="450" height="600" align=center />
<h1 id="visualize-cnn-filter-by-gradient-ascent">Visualize CNN filter by gradient ascent</h1>
<p>Filter visualization displays the features extracted by a convolution kernel, it's used to explain the model.<br>
Randomly choosing some filters in the target convolution layer, then get their gradient loss and do gradient ascent to add gradient loss on random noise, we can find what features those filters are extracting.<br>
<img src="../../post-images/20200910_2.png" width="400" height="400" align=center /></p>
<p>Adding gradient loss of each filter on the origin image, we can find out what those filters do on our images. The following image demonstrated  that the last conv layer can extract eyes and facial contour features.<br>
<img src="../../post-images/20200910_3.png" width="400" height="400" align=center /></p>
<h1 id="saliency-map">Saliency Map</h1>
<p>In saliency map, we find the important areas on the face are highlighted by neural networks.<br>
<img src="../../post-images/20200910_4.jpg" width="150" height="150" align=center /><br>
<img src="../../post-images/20200910_5.jpg" width="150" height="150" align=center /></p>
<h1 id="confusion-matrix">Confusion Matrix</h1>
<p>In the training data set, the &quot;disgust&quot; data are rare, therefore, for other kinds of sentiment, it's not easy to be misjudged as disgust.<br>
<img src="../../post-images/20200910_6.jpg" width="500" height="500" align=center /></p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li><a href="#resources">Resources</a></li>
<li><a href="#task">Task</a></li>
<li><a href="#data-augmentation">Data augmentation</a></li>
<li><a href="#image-contrast-enhancement">Image Contrast Enhancement</a></li>
<li><a href="#model">Model</a></li>
<li><a href="#visualize-cnn-filter-by-gradient-ascent">Visualize CNN filter by gradient ascent</a></li>
<li><a href="#saliency-map">Saliency Map</a></li>
<li><a href="#confusion-matrix">Confusion Matrix</a></li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">Next</div>
            <a href="https://lhf2011.github.io/post/graph-neural-network-gcn-dgcnn/">
              <h3 class="post-title">
                Graph neural network - GCN, DGCNN
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://lhf2011.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
