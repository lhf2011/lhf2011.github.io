<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Segmentation Known Issues | Gridea</title>
<link rel="shortcut icon" href="https://lhf2011.github.io/favicon.ico?v=1624435026958">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://lhf2011.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="Segmentation Known Issues | Gridea - Atom Feed" href="https://lhf2011.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="Libs preparation
pytorch
torch2trt
1, Run the pytorch model on your cuda platform
Command:
python seg.py --pred_by_pytor..." />
    <meta name="keywords" content="" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://lhf2011.github.io">
  <img class="avatar" src="https://lhf2011.github.io/images/avatar.png?v=1624435026958" alt="">
  </a>
  <h1 class="site-title">
    Gridea
  </h1>
  <p class="site-description">
    Be good. 
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          Index
        </a>
      
    
      
        <a href="/archives" class="menu">
          Archives
        </a>
      
    
      
        <a href="/tags" class="menu">
          Tags
        </a>
      
    
      
        <a href="/post/about" class="menu">
          About
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Segmentation Known Issues
            </h2>
            <div class="post-info">
              <span>
                2021-06-20
              </span>
              <span>
                2 min read
              </span>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <h1 id="libs-preparation">Libs preparation</h1>
<p>pytorch<br>
torch2trt</p>
<h1 id="1-run-the-pytorch-model-on-your-cuda-platform">1, Run the pytorch model on your cuda platform</h1>
<p>Command:</p>
<pre><code class="language-shell">python seg.py --pred_by_pytorch
</code></pre>
<p>If successful, there will be log print in terminal:</p>
<pre><code class="language-shell">segmentation cost time: 0.009063 , move data from cuda to cpu cost time: 0.105587
</code></pre>
<p>In this log, the cost time of moving date(0.105587) is far more larger than segmentation(0.009063), it cost more time when the image size increase.</p>
<h1 id="2-convert-the-python-model-to-be-applied-in-c-libtorch">2, Convert the python model to be applied in C++ libtorch</h1>
<p>Command:</p>
<pre><code class="language-shell">python seg.py --pytorch2cpp
</code></pre>
<p>Issue: Error happens.</p>
<h1 id="3-convert-the-pytorch-model-to-onnx-and-tensorrt-engine-and-run-it">3, Convert the pytorch model to ONNX and tensorrt engine, and run it.</h1>
<p>Command:</p>
<pre><code class="language-shell">python seg.py --torch2onnx --onnx2trt
</code></pre>
<p>If successful, there will be 2 models generated under “./model/segmentation_module”, there are “segmentation_module.onnx” and “segmentation_module.trt”.<br>
Then run:</p>
<pre><code class="language-shell">python seg.py --pred_by_onnx2trt
</code></pre>
<p>If successful, there will be log print in terminal:</p>
<pre><code class="language-shell">segmentation cost time(): 0.123997
</code></pre>
<p>And the segmentation result will be saved in “./input/2021-03-16-11-30-12_4/seg_color.jpg”.<br>
Issue: Check the segmentation result “seg_color.jpg”, it shows a correct contour, but the prediction is not correct. The same issue happens when the ONNX model runs in openvino.</p>
<img src="../post-images/20200909_1.png" width="200" height="180" align=center />
<h1 id="4-convert-the-pytorch-model-to-tensorrt-script-and-run-it">4, Convert the pytorch model to tensorrt script, and run it.</h1>
<p>Command:</p>
<pre><code class="language-shell">python seg.py --torch2trt
</code></pre>
<p>If successful, there will be a model “segmentation_module.pth” generated under “./model/segmentation_module”.<br>
Then run:</p>
<pre><code class="language-shell">python seg.py --pred_by_torch2trt
</code></pre>
<p>If successful, there will be log print in terminal:</p>
<pre><code class="language-shell">segmentation cost time: 0.002163
</code></pre>
<p>And the segmentation result will be saved in “./input/2021-03-16-11-30-12_4/seg_color.jpg”, and this result should be correct.</p>
<img src="../post-images/20200909_1.png" width="200" height="180" align=center />

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li><a href="#libs-preparation">Libs preparation</a></li>
<li><a href="#1-run-the-pytorch-model-on-your-cuda-platform">1, Run the pytorch model on your cuda platform</a></li>
<li><a href="#2-convert-the-python-model-to-be-applied-in-c-libtorch">2, Convert the python model to be applied in C++ libtorch</a></li>
<li><a href="#3-convert-the-pytorch-model-to-onnx-and-tensorrt-engine-and-run-it">3, Convert the pytorch model to ONNX and tensorrt engine, and run it.</a></li>
<li><a href="#4-convert-the-pytorch-model-to-tensorrt-script-and-run-it">4, Convert the pytorch model to tensorrt script, and run it.</a></li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">Next</div>
            <a href="https://lhf2011.github.io/post/skills-in-gridea/">
              <h3 class="post-title">
                Skills in Gridea
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://lhf2011.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
